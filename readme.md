"Grad-CAM" and "Saliency Maps" are two techniques used in computer vision to understand and visualize the important regions or features that influence the predictions of a deep learning model.

# Grad-CAM :
Grad-CAM is a technique that generates a heatmap highlighting the regions in an input image that contribute most to the model's prediction for a specific class. It utilizes the gradients flowing into the final convolutional layer of a convolutional neural network (CNN) to determine the importance of each pixel or feature map. By examining the gradients, Grad-CAM generates a class activation map, indicating the regions that are most relevant for the network's prediction. This technique helps in understanding which parts of the image the network focuses on to make its decision.

# Saliency Maps:
Saliency maps are a simpler technique used to visualize the regions of an input image that are most relevant to the predictions of a deep learning model. Saliency maps are typically generated by computing the gradients of the model's output with respect to the input image. These gradients indicate how sensitive the model's prediction is to changes in each pixel of the input image. By visualizing these gradients or assigning weights to the pixels based on their magnitude, a saliency map is created, highlighting the regions that contribute significantly to the model's decision-making process.


# What do saliency map and Gradcam tell you? How are they different? Is one better than the other?

Both of them tell us what the neural net thinks is important in the input for making itâ€™s decisions.
Saliency map tells the sensitivity of the loss(scores) to small input pixel changes. 
Gradcam highlights regions of importance in the image, that is regions that have high gradients in the last activation layer w.r.t. output class scores. I do not think one is generally better than the other, but both combined (like guided Gradcam ) can yield better results. Saliency maps are more high resolution highlighting fine grained details in the
image and are also not limited to CNNs because they are only gradient based. Gradcam is
more class discriminative and gives better visualization but is generally limited to CNNs.

# What insights do you get from fooling images:

- We can fool a neural network, even one that generalized well, using adversarial images
that are almost indistinguishable from the original image.
- A possible explanation is that discriminative training leads networks to ignore generic
features. e.g. learning to detect jaguars by matching the unique spots on their fur while
ignoring the fact that they have four legs like most animals [2].
- This might also be related to the idea that the model might be biased towards texture not
shape. As in this paper: https://arxiv.org/abs/1811.12231
- If we mess especially with the regions of the image that the model considers important
we could much more easily fool the model.

